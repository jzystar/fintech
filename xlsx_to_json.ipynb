{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment counter: 1423\n",
      "sentiment year start ids： {'2019': 0, '2020': 244, '2021': 487, '2022': 730, '2023': 972, '2024': 1185}\n",
      "earning_rate counter: 1423\n",
      "earning_rate year start ids： {'2019': 0, '2020': 244, '2021': 487, '2022': 730, '2023': 972, '2024': 1185}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "file_paths = [r\"./data/复盘记录2019.xlsx\",\n",
    "             r\"./data/复盘记录2020.xlsx\",\n",
    "             r\"./data/复盘记录2021.xlsx\",\n",
    "             r\"./data/复盘记录2022.xlsx\",\n",
    "             r\"./data/复盘记录2023.xlsx\",\n",
    "             r\"./data/复盘记录2024.xlsx\"]\n",
    "             \n",
    "eval_paths = [r\"./data/复盘记录2025.xlsx\"]\n",
    "# selected_cols = (\"日期\", \"大盘量比\", \"涨幅\", \"涨跌停比\", '赚钱效应', '市场情绪', '炸板率', '连板数', '昨板今均', '今日概况')\n",
    "sentiment_selected_cols = (\"大盘量比\", \"涨幅\", \"涨跌停比\", '赚钱效应', '市场情绪', '炸板率', '连板数', '昨板今均')\n",
    "earning_rate_selected_cols = (\"大盘量比\", \"涨幅\", \"涨跌停比\", '赚钱效应', '炸板率', '连板数', '昨板今均')\n",
    "\n",
    "percent_cols = ['赚钱效应',  '炸板率']\n",
    "\n",
    "\n",
    "def parse_file(file_paths, selected_cols, percent_cols):\n",
    "    result_rows = []\n",
    "    start_id_of_year = {}\n",
    "    for path in file_paths:\n",
    "        year = path[11:15]\n",
    "        start_id_of_year[year] = len(result_rows)\n",
    "        df = pd.read_excel(path)\n",
    "        # print(\"原始数据形状 (行数, 列数):\", df.shape)\n",
    "        # print(\"\\n列名:\", list(df.columns))\n",
    "\n",
    "        # 获取列名（表头）\n",
    "        headers = df.columns.tolist()\n",
    "        # print(headers)\n",
    "        for idx, row in df.iterrows():\n",
    "            row_data = []\n",
    "            # # 处理NaN值\n",
    "            if pd.isna(row[\"日期\"]):\n",
    "                continue\n",
    "            # 遍历每一列\n",
    "            for header in selected_cols:\n",
    "                # 添加表头前缀到元素值\n",
    "                value = row[header]\n",
    "                # print(idx, header, value)\n",
    "                if header == \"日期\":\n",
    "                    value = value.strftime('%Y-%m-%d')\n",
    "                if header in percent_cols and '%' not in str(value):\n",
    "                    value = f\"{float(value) * 100:.2f}%\"\n",
    "                if header == \"涨幅\":\n",
    "                    header = \"大盘涨幅\"\n",
    "                if header == \"昨板今均\":\n",
    "                    header = \"昨日涨停表现\"\n",
    "                # 情绪变为（超级差，很差，差，一般，好，很好，超级好）\n",
    "                if header == \"市场情绪\":\n",
    "                    # print(f\"old 情绪value {value}\")\n",
    "                    value = value.split('(')[0].split('（')[0]\n",
    "                    value = value.replace(\"股灾\", \"超级差\")\n",
    "                    value = value.replace(\"极差\", \"很差\")\n",
    "                    value = value.replace(\"极好\", \"很好\")\n",
    "                    value = value.replace(\"爆炸好\", \"超级好\")\n",
    "                    # print(f\"new 情绪value {value}\")\n",
    "\n",
    "                if header == \"涨跌停比\":\n",
    "                    tmp  = re.split(':|：', value)\n",
    "                    formatted_value = f\"涨停数量{tmp[0]}， 跌停数量{tmp[1]}\"\n",
    "                    # print(formatted_value)\n",
    "                else:\n",
    "                    formatted_value = f\"{header}{value}\"\n",
    "                row_data.append(formatted_value)\n",
    "            # print(row_data)\n",
    "            # 将处理后的行添加到结果列表\n",
    "            # result_rows.append(\"， \".join(row_data))\n",
    "            result_rows.append(row_data)\n",
    "    return result_rows, start_id_of_year\n",
    "\n",
    "result_rows_sentiment, start_id_of_year_sentiment = parse_file(file_paths, sentiment_selected_cols, percent_cols)\n",
    "result_rows_earning_rate, start_id_of_year_earning_rate = parse_file(file_paths, earning_rate_selected_cols, percent_cols)\n",
    "eval_data_sentiment, _ = parse_file(eval_paths, sentiment_selected_cols, percent_cols)\n",
    "eval_data_earning_rate, _ = parse_file(eval_paths, earning_rate_selected_cols, percent_cols)\n",
    "\n",
    "\n",
    "print(f\"sentiment counter: {len(result_rows_sentiment)}\")\n",
    "print(f\"sentiment year start ids： {start_id_of_year_sentiment}\")\n",
    "\n",
    "print(f\"earning_rate counter: {len(result_rows_earning_rate)}\")\n",
    "print(f\"earning_rate year start ids： {start_id_of_year_earning_rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def find_col_id(data, target):\n",
    "    for i, s in enumerate(data):\n",
    "        if s.find(target) != -1:\n",
    "            return i\n",
    "    return -1\n",
    "\n",
    "def produce_train_data(dataset, date_span, predict_col=\"市场情绪\"):\n",
    "\n",
    "    json_data = []\n",
    "    input = \"\"\n",
    "    note = \"\"\n",
    "    if predict_col==\"市场情绪\":\n",
    "        note = \"市场情绪分类范围是：超级差、很差、差、一般、好、很好、超级好。程度由坏到好。\"\n",
    "    if predict_col == \"赚钱效应\":\n",
    "        note = \"赚钱效应区间有3个，分别是：0-35%、35%-70%、70%-100%。\"\n",
    "    for i in range(len(dataset)):\n",
    "        date_id = (i + 1) % (date_span + 1)\n",
    "        if date_id:\n",
    "            cur_data = f'第{date_id}天大盘数据是:' + '， '.join(dataset[i]) + '。\\n'\n",
    "            input += cur_data\n",
    "        else:\n",
    "            predict_col_id = find_col_id(dataset[i], predict_col)\n",
    "            assert predict_col_id != -1\n",
    "            output = dataset[i][predict_col_id][len(predict_col):]\n",
    "            predict_name = predict_col\n",
    "            if predict_name == \"赚钱效应\":\n",
    "                predict_name += \"区间\"\n",
    "            json_entry = {\n",
    "                \"instruction\": f\"请你根据近{date_span}天的数据，来预测下一天的{predict_name}。\",\n",
    "                \"input\": input + note + \"请你一步步的推理分析，最终<answer>里的答案必须是在这个范围内，而且只给出一个答案。\\n\",\n",
    "                \"output\": output\n",
    "            }\n",
    "            input = \"\"\n",
    "            json_data.append(json_entry)\n",
    "\n",
    "    print(f\"\\n共 {len(json_data)} 条记录\")\n",
    "    return json_data\n",
    "\n",
    "def produce_train_data_single_day(dataset, predict_col=\"市场情绪\"):\n",
    "\n",
    "    json_data = []\n",
    "    note = \"\"\n",
    "    if predict_col==\"市场情绪\":\n",
    "        note = \"市场情绪分类范围是：超级差、很差、差、一般、好、很好、超级好。程度由坏到好。\"\n",
    "    if predict_col == \"赚钱效应\":\n",
    "        note = \"赚钱效应区间有3个，分别是：0-35%、35%-70%、70%-100%。\"\n",
    "    for i in range(len(dataset)):\n",
    "        \n",
    "        predict_col_id = find_col_id(dataset[i], predict_col)\n",
    "        assert predict_col_id != -1\n",
    "        output = dataset[i][predict_col_id][len(predict_col):]\n",
    "        # print(output)\n",
    "        data = dataset[i].copy()\n",
    "        del data[predict_col_id]\n",
    "        input = '， '.join(data) + '。\\n'\n",
    "        predict_name = predict_col\n",
    "        if predict_name == \"赚钱效应\":\n",
    "            predict_name += \"区间\"\n",
    "        json_entry = {\n",
    "            \"instruction\": f\"请你根据一些当天的市场数据，来预测当天的{predict_name}。\",\n",
    "            \"input\": \"当天市场数据是：\" + input + note + \"请你一步步的推理分析，最终<answer>里的答案必须是在这个范围内，而且只给出一个答案。\\n\",\n",
    "            \"output\": output\n",
    "        }\n",
    "        json_data.append(json_entry)\n",
    "\n",
    "    print(f\"\\n共 {len(json_data)} 条记录\")\n",
    "    return json_data\n",
    "# sentiment_single_day = produce_train_data_single_day(result_rows_sentiment)\n",
    "# print(sentiment_single_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "共 355 条记录\n",
      "start id is  972\n",
      "\n",
      "数据已保存为 ./dataset/sentiment_data_3.json，共 355 条记录\n",
      "\n",
      "共 112 条记录\n",
      "\n",
      "数据已保存为 ./dataset/sentiment_data_enchanced_3.json，共 467 条记录\n",
      "\n",
      "共 237 条记录\n",
      "\n",
      "数据已保存为 ./dataset/sentiment_data_5.json，共 237 条记录\n",
      "\n",
      "共 74 条记录\n",
      "\n",
      "数据已保存为 ./dataset/sentiment_data_enchanced_5.json，共 311 条记录\n",
      "\n",
      "共 10 条记录\n",
      "\n",
      "eval数据已保存为 ./dataset/sentiment_eval.json，共 10 条记录\n",
      "\n",
      "共 1423 条记录\n",
      "\n",
      "single day数据已保存为 ./dataset/sentiment_single_day.json，共 1423 条记录\n",
      "\n",
      "共 42 条记录\n",
      "\n",
      "eval数据已保存为 ./dataset/sentiment_eval_single_day.json，共 42 条记录\n"
     ]
    }
   ],
   "source": [
    "output_file1 = './dataset/sentiment_data_3.json'\n",
    "output_file2 = './dataset/sentiment_data_enchanced_3.json'\n",
    "output_file3 = './dataset/sentiment_data_5.json'\n",
    "output_file4 = './dataset/sentiment_data_enchanced_5.json'\n",
    "output_file5 = './dataset/sentiment_eval.json'\n",
    "output_file6 = './dataset/sentiment_single_day.json'\n",
    "output_file7 = './dataset/sentiment_eval_single_day.json'\n",
    "predict = '市场情绪'\n",
    "\n",
    "\n",
    "json_data1 = produce_train_data(result_rows_sentiment, 3, predict)\n",
    "with open(output_file1, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_data1, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "start = start_id_of_year_sentiment['2023']\n",
    "print(\"start id is \", start)\n",
    "print(f\"\\n数据已保存为 {output_file1}，共 {len(json_data1)} 条记录\")\n",
    "# 保存为JSON文件\n",
    "json_data2 = produce_train_data(result_rows_sentiment[start + 2:], 3, predict)\n",
    "combined1 = json_data1 + json_data2\n",
    "with open(output_file2, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined1, f, ensure_ascii=False, indent=4)\n",
    "print(f\"\\n数据已保存为 {output_file2}，共 {len(combined1)} 条记录\")\n",
    "\n",
    "json_data3 = produce_train_data(result_rows_sentiment, 5, predict)\n",
    "with open(output_file3, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_data3, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\n数据已保存为 {output_file3}，共 {len(json_data3)} 条记录\")\n",
    "# 保存为JSON文件\n",
    "json_data4 = produce_train_data(result_rows_sentiment[start + 2:], 5, predict)\n",
    "combined2 = json_data3 + json_data4\n",
    "with open(output_file4, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined2, f, ensure_ascii=False, indent=4)\n",
    "print(f\"\\n数据已保存为 {output_file4}，共 {len(combined2)} 条记录\")\n",
    "\n",
    "\n",
    "json_data_eval = produce_train_data(eval_data_sentiment, 3, predict)\n",
    "with open(output_file5, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_data_eval, f, ensure_ascii=False, indent=4)\n",
    "print(f\"\\neval数据已保存为 {output_file5}，共 {len(json_data_eval)} 条记录\")\n",
    "\n",
    "json_data_single_day = produce_train_data_single_day(result_rows_sentiment)\n",
    "with open(output_file6, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_data_single_day, f, ensure_ascii=False, indent=4)\n",
    "print(f\"\\nsingle day数据已保存为 {output_file6}，共 {len(json_data_single_day)} 条记录\")\n",
    "\n",
    "\n",
    "json_data_eval_single_day = produce_train_data_single_day(eval_data_sentiment)\n",
    "with open(output_file7, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_data_eval_single_day, f, ensure_ascii=False, indent=4)\n",
    "print(f\"\\neval数据已保存为 {output_file7}，共 {len(json_data_eval_single_day)} 条记录\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "共 355 条记录\n",
      "start id is  972\n",
      "\n",
      "数据已保存为 ./dataset/earning_rate_data_3.json，共 355 条记录\n",
      "\n",
      "共 112 条记录\n",
      "\n",
      "数据已保存为 ./dataset/earning_rate_data_enchanced_3.json，共 467 条记录\n",
      "\n",
      "共 237 条记录\n",
      "\n",
      "数据已保存为 ./dataset/earning_rate_data_5.json，共 237 条记录\n",
      "\n",
      "共 74 条记录\n",
      "\n",
      "数据已保存为 ./dataset/earning_rate_data_enchanced_5.json，共 311 条记录\n",
      "\n",
      "共 10 条记录\n",
      "\n",
      "eval数据已保存为 ./dataset/earning_rate_eval.json，共 10 条记录\n"
     ]
    }
   ],
   "source": [
    "output_file1 = './dataset/earning_rate_data_3.json'\n",
    "output_file2 = './dataset/earning_rate_data_enchanced_3.json'\n",
    "output_file3 = './dataset/earning_rate_data_5.json'\n",
    "output_file4 = './dataset/earning_rate_data_enchanced_5.json'\n",
    "output_file5 = './dataset/earning_rate_eval.json'\n",
    "predict = '赚钱效应'\n",
    "\n",
    "json_data1 = produce_train_data(result_rows_earning_rate, 3, predict)\n",
    "with open(output_file1, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_data1, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "start = start_id_of_year_earning_rate['2023']\n",
    "print(\"start id is \", start)\n",
    "print(f\"\\n数据已保存为 {output_file1}，共 {len(json_data1)} 条记录\")\n",
    "# 保存为JSON文件\n",
    "json_data2 = produce_train_data(result_rows_earning_rate[start + 2:], 3, predict)\n",
    "combined1 = json_data1 + json_data2\n",
    "with open(output_file2, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined1, f, ensure_ascii=False, indent=4)\n",
    "print(f\"\\n数据已保存为 {output_file2}，共 {len(combined1)} 条记录\")\n",
    "\n",
    "json_data3 = produce_train_data(result_rows_earning_rate, 5, predict)\n",
    "with open(output_file3, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_data3, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"\\n数据已保存为 {output_file3}，共 {len(json_data3)} 条记录\")\n",
    "# 保存为JSON文件\n",
    "json_data4 = produce_train_data(result_rows_earning_rate[start + 2:], 5, predict)\n",
    "combined2 = json_data3 + json_data4\n",
    "with open(output_file4, 'w', encoding='utf-8') as f:\n",
    "    json.dump(combined2, f, ensure_ascii=False, indent=4)\n",
    "print(f\"\\n数据已保存为 {output_file4}，共 {len(combined2)} 条记录\")\n",
    "\n",
    "\n",
    "json_data_eval = produce_train_data(eval_data_earning_rate, 3, predict)\n",
    "with open(output_file5, 'w', encoding='utf-8') as f:\n",
    "    json.dump(json_data_eval, f, ensure_ascii=False, indent=4)\n",
    "print(f\"\\neval数据已保存为 {output_file5}，共 {len(json_data_eval)} 条记录\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
